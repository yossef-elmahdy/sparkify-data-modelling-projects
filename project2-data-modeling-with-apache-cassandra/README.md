# Project 2: Data Modeling with Apache Cassandra (NoSQL) 
Applying what I have learned on data modeling with Apache Cassandra and complete an ETL pipeline using Python. To complete the project, I needed to model my data by creating tables in Apache Cassandra to run queries. I was provided with part of the ETL pipeline that transfers data from a set of CSV files within a directory to create a streamlined CSV file to model and insert data into Apache Cassandra tables.

## Project Template
To get started with the project you'll find the project template ([a Jupyter notebook file](#TO-DO)). You can work on your project and submit your work through this workspace.

The project template includes one Jupyter Notebook file, in which:
- Process the `event_datafile_new.csv` dataset to create a denormalized dataset
- Model the data tables keeping in mind the queries you need to run. 
- Load the data into tables you create in Apache Cassandra and run your queries. 

![Project CSV Data](https://github.com/yossef-elmahdy/sparkify-data-modelling-projects/blob/main/project2-data-modeling-with-apache-cassandra/image_event_datafile_new.jpg)


